{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation of Stackoverflow surveys for job satisfaction\n",
    "\n",
    "This notebook looks at stackoverflow surveys duriring five consequent years from 2015-2020 with the aim to realize general job satisfaction of developers according to the surveys [here](https://insights.stackoverflow.com/survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "survey = \"./surveys_results/survey_results_public_\"\n",
    "mod_df = \"./modified_results/modified_survey_results_public_\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 surveys results stored as CSV format in \"surveys_results\" folder. Each year there are differnces in questionier asked from IT persons/Develpoers to answer them. But there are some questions repeated in each year. Our focus is to use fields in the results that belong to such questions like country of residence or salary.\n",
    "First we look to country of residence from the 2015 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading country results from 2016 and 2015\n",
    "df_2015 = pd.read_csv(survey+\"2015.csv.gz\", usecols=['Country'], skiprows=1, compression='gzip') #2015 country results\n",
    "\n",
    "df_2018 = pd.read_csv(survey+\"2018.csv.gz\", usecols=['Country'], compression='gzip') #2016 country results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look to number of unique countries in these two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of 2015: 157\n",
      "Lenght of 2018: 181\n"
     ]
    }
   ],
   "source": [
    "# 2015 unique countries\n",
    "print(\"Lenght of 2015:\", len(df_2015.Country.unique()))\n",
    "print(\"Lenght of 2018:\", len(df_2018.Country.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different number of ccountries in each dataframe. Also there are some countries which have different naming in each one of these surveys. For example 'Viet Nam' in 2018 and 'Vietnam' in 2015 or 'Syria' in 2015 and 'Syrian Arab Republic' in 2018. Also there is 'un_subregion' column in 2016 results which not exist in other results. For this reason we have to modify columns values to have same value names and later we can categorize them like having **continent** or **subregion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of... , Hong Kong , Other Country (Not Listed Above) , Micronesia , Yemen , Fiji , Burundi , Lesotho , Marshall Islands , Malawi , Libya , Guinea , Côte d'Ivoire , Central African Rep , Monaco , Gambia , Palau , Grenada , Belize , Suriname , East Timor , Dominica , Saint Lucia , Niger , Guyana , Nauru , Mali , Liberia , Cape Verde , Eritrea , Guinea-Bissau , "
     ]
    }
   ],
   "source": [
    "# example of dis-similarity between country names in data sets.\n",
    "unique_2018 =[]\n",
    "for x in df_2018.Country.unique():\n",
    "    unique_2018.append(x)\n",
    "\n",
    "unique_2015 =[]\n",
    "for x in df_2015.Country.unique():\n",
    "    unique_2015.append(x)\n",
    "    \n",
    "for x in unique_2018:\n",
    "    if x not in unique_2015:\n",
    "        print(x,', ',end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Removing dissimilarity among datasets\n",
    " \n",
    " Removing differences in country names. Adding 'un-subregion' and 'Continent' to data sets by creating new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be used for reding 2015 results \n",
    "col_2015=['Country','Age','Gender',\n",
    "          'Training & Education: BS in CS',\n",
    "          'Training & Education: No formal training',\n",
    "          'Training & Education: Some college, but no CS degree',\n",
    "          'Training & Education: Masters in CS',\n",
    "          'Training & Education: PhD in CS','Compensation',\n",
    "          'Employment Status','Job Satisfaction']\n",
    "\n",
    "# Reading selected columns\n",
    "df_2015 = pd.read_csv(\"./surveys_results/survey_results_public_\"+\"2015.csv.gz\", \n",
    "                      usecols=col_2015, skiprows=1, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find differnces in country names we check all the data sets with one unique list loaded from  **'country_continent.csv'** file. So we can add continent and subregion to data frame which miss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading list of countries and their properties\n",
    "df_country = pd.read_csv('./country_continent.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "uniques =[]\n",
    "for x in df_country.country.unique():\n",
    "    uniques.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which countries have different name from this list and modify them for 2015 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2015.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Prefer not to disclose', 'Female', nan, 'genderqueer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education\n",
    "In 2015 survey results university education level are separated in different cloumns. Lets create one column as **'FormalEducation'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_null_col = df_2015\n",
    "edu_col = ['Training & Education: BS in CS','Training & Education: No formal training',\n",
    "           'Training & Education: Some college, but no CS degree',\n",
    "           'Training & Education: Masters in CS',\n",
    "           'Training & Education: PhD in CS']\n",
    "\n",
    "# This dictionary used to make consistency between all survey results\n",
    "edu_value={'Training & Education: BS in CS':\"Bachelor degree (BA, BS, B.Eng., etc.)\",\n",
    "          'Training & Education: No formal training':\"I never completed any formal education\",\n",
    "          'Training & Education: Some college, but no CS degree':\"Some college/university study without earning a degree\",\n",
    "          'Training & Education: Masters in CS':\"Master degree (MA, MS, M.Eng., MBA, etc.)\",\n",
    "          'Training & Education: PhD in CS':\"Other doctoral degree (Ph.D, Ed.D., etc.)\"}\n",
    "\n",
    "not_null_col = [] # store not null columns\n",
    "\n",
    "# creating new column as 'FormalEducation' education and updating it's value\n",
    "for col in edu_col:\n",
    "    not_null_col = df_2015[col][df_2015[col].notnull()==True].index\n",
    "    df_2015.loc[not_null_col,'FormalEducation']=edu_value[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Master degree (MA, MS, M.Eng., MBA, etc.)', nan,\n",
       "       'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
       "       'I never completed any formal education',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check FormalEducation column\n",
    "df_2015.FormalEducation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the other 5 columns by having new **'FormalEducation'** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping education columns\n",
    "df_2015.drop(columns=edu_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting N/A value of country to nan\n",
    "#df_2015.loc[df_2015['Country']=='N/A', 'Country']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_2015['Country'].isnull()==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continent and subregion\n",
    "Adding **'un_subregion'** and **'Continent'** columns for further comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2015['Country'].isnull()\n",
    "\n",
    "for i in range(df_2015.shape[0]):\n",
    "    x = df_2015.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2015.shape[0]:\n",
    "    df_2015['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2015.shape[0]:\n",
    "        df_2015['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender\n",
    "To check the relation between gender and job satisfaction we categorize them in main 3 different categories: Male, Female and genderqueer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Prefer not to disclose', 'Female', nan, 'Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique values in 2015 survey for gender is as follow\n",
    "df_2015.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'Other' to 'genderqueer' to make consistency\n",
    "df_2015.Gender.replace('Other', 'genderqueer', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status\n",
    "For consistency between all other surveys we need to replace following values to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values in the 'Employment Status' which will be replaced by other values\n",
    "col = [\"I'm a student\",\"Prefer not to disclose\"]\n",
    "\n",
    "# Modified values \n",
    "mod = [\"Student\", \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2015['Employment Status'].replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "To make answers be consistent between all the surveys, replace the values in job satisfaction column as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"I'm somewhat satisfied with my job\",\n",
    "       \"I'm neither satisfied nor dissatisfied with my job\",\n",
    "       \"I love my job\",\n",
    "       \"I'm somewhat dissatisfied with my job\",\n",
    "       \"I hate my job\",\n",
    "       \"Other (please specify)\"]\n",
    "\n",
    "mod = [\"Moderately satisfied\",\n",
    "       \"Neither satisfied nor dissatisfied\",\n",
    "       \"Extremely satisfied\",\n",
    "       \"Slightly dissatisfied\",\n",
    "       \"Extremely dissatisfied\",\n",
    "       \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2015['Job Satisfaction'].replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last thing : saving new dataframe df_2015 for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2015.to_csv(mod_df+\"2015.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Professional', 'Country', 'EmploymentStatus', 'FormalEducation',\n",
       "       'CompanySize', 'CareerSatisfaction', 'JobSatisfaction', 'JobSecurity',\n",
       "       'Gender', 'Salary', 'ExpectedSalary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataframe\n",
    "col_2016=['country','un_subregion','age_range','gender',\n",
    "          'salary_range','employment_status',\n",
    "          'company_size_range','job_satisfaction','education']\n",
    "\n",
    "df_2016 =  pd.read_csv(survey+'2016.csv.gz',usecols=col_2016, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and Continent\n",
    "First we make the country become same with our refrence also adding 'Continent' column to dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other (please specify) \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2016.country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one difference **'Other (please specify)'**. If any cell value in country column  **'un_subregion'**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding index of the rows with 'Other (please specify)'\n",
    "index = df_2016[df_2016['country']=='Other (please specify)'].index\n",
    "\n",
    "# changing their value to 'Other'\n",
    "df_2016.loc[index,'country'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2016['country'].isnull()\n",
    "\n",
    "for i in range(df_2016.shape[0]):\n",
    "    x = df_2016.iloc[i]['country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2016.shape[0]:\n",
    "    df_2016['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2016.shape[0]:\n",
    "        df_2016['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If continent and subregion added as without any problem we drop old un_subregion column\n",
    "df_2016.drop(columns=['un_subregion'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment status\n",
    "There is only one difference between 2015 and 2016 employment status and it's the 'Other' and 'Other (please specify)'. Lets make it be 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for employment status make consistency between their values\n",
    "df_2016.employment_status.loc[df_2016.employment_status=='Other (please specify)'] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal Education\n",
    "In 2016 results the field of education have multiple decisions as string in each row. We need to make a new 'FormalEducation' column with selected option from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm self-taught; On-the-job training; B.S. in Computer Science (or related field)\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of concatanated example\n",
    "df_2016.education[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all unique education strings from the dataframe\n",
    "edu_strings = df_2016.education.unique()\n",
    "\n",
    "# separate strings found by split function\n",
    "splited_list = []\n",
    "\n",
    "for edu in edu_strings:\n",
    "    if type(edu) != int and type(edu) != float:\n",
    "        for x in edu.split('; '):\n",
    "            if x not in splited_list:\n",
    "                splited_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm self-taught\",\n",
       " 'On-the-job training',\n",
       " 'B.S. in Computer Science (or related field)',\n",
       " 'Online class (e.g. Coursera, Codecademy, Khan Academy, etc.)',\n",
       " 'B.A. in Computer Science (or related field)',\n",
       " 'Masters Degree in Computer Science (or related field)',\n",
       " 'Some college coursework in Computer Science (or related field)',\n",
       " 'Full-time, intensive program (e.g. \"boot-camp\")',\n",
       " 'Industry certification program',\n",
       " 'PhD in Computer Science (or related field)',\n",
       " 'Part-time program (e.g. night school)',\n",
       " 'Mentorship program (e.g. Flatiron School, GDI, etc.)']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Founded unique strings\n",
    "splited_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wee need to check each column and put the match into 'FormalEducation' list to be similar to 2015 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Master degree (MA, MS, M.Eng., MBA, etc.)', nan,\n",
       "       'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
       "       'I never completed any formal education',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values in 2015 for fomal education\n",
    "df_2015.FormalEducation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column succesfully added\n"
     ]
    }
   ],
   "source": [
    "# dictionary for equivalent string\n",
    "edu_dic={\"I'm self-taught\": 'I never completed any formal education',\n",
    "        'B.S. in Computer Science (or related field)':'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
    "        'B.A. in Computer Science (or related field)':'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
    "        'Masters Degree in Computer Science (or related field)':'Master degree (MA, MS, M.Eng., MBA, etc.)',\n",
    "        'PhD in Computer Science (or related field)':'Other doctoral degree (Ph.D, Ed.D., etc.)'}\n",
    "\n",
    "# check if key exist in a dictionary or not\n",
    "def checkKey(dict, key):\n",
    "    if key in dict.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# finding equivalent degree for each syrvey result\n",
    "formal_edu=[]\n",
    "for edu_str in df_2016.education:\n",
    "    if type(edu_str) != int and type(edu_str) != float:\n",
    "        edu_list = edu_str.split('; ')\n",
    "        check = True\n",
    "        value=''\n",
    "        for x in edu_list:\n",
    "            if checkKey(edu_dic, x) and check:\n",
    "                check=False\n",
    "                value=edu_dic[x]\n",
    "        if check:\n",
    "            formal_edu.append('I never completed any formal education')\n",
    "        else:\n",
    "            formal_edu.append(value)\n",
    "    else:\n",
    "        formal_edu.append(np.nan)\n",
    "\n",
    "# Adding new column as 'FormalEducation' to dataframe\n",
    "if len(formal_edu) == df_2016.shape[0]:\n",
    "    df_2016['FormalEducation'] = formal_edu\n",
    "    print('New column succesfully added')\n",
    "else:\n",
    "    print('error: size mismatch to add new column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Size\n",
    "Now we check the company size values and make it consistent to what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '100-500', 'I am not part of a company', '10-19',\n",
       "       '5-9 employees', '20-99', '<10', '500-999', '1000', '10000+',\n",
       "       '5000-9999', 'I am not sure', 'I prefer not to answer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.company_size_range.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column values\n",
    "col = [\"100-499 employees\",\"I am not part of a company\",\"10-19 employees\",\n",
    "       \"5-9\temployees\",\"20-99 employees\",\"1-4 employees\",\n",
    "       \"500-999 employees\",\"1,000-4,999 employees\",\"10,000+ employees\",\n",
    "       \"5,000-9,999 employees\",\"I am not sure\",\"Other (please specify)\"] #Changing thses to new one\n",
    "\n",
    "# Modified values\n",
    "mod = [\"100-500\",\"I am not part of a company\",\n",
    "       \"10-19\",\"<10\",\"20-99\",\"<10\",\"500-999\",\n",
    "       \"1000\",\"10000+\",\"5000-9999\",\"I am not sure\",\n",
    "       \"I prefer not to answer\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2016.company_size_range.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Age', 'Gender', 'Compensation', 'Employment Status',\n",
       "       'Job Satisfaction', 'FormalEducation', 'UN_subregion', 'Continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.salary_range.unique()\n",
    "df_2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.salary_range.replace('Other (please specify)','Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "Change the values of job satisfaction column for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"I love my job\",\n",
    "       \"I don't have a job\",\n",
    "       \"I'm somewhat satisfied with my job\",\n",
    "       \"I'm somewhat dissatisfied with my job\",\n",
    "       \"I'm neither satisfied nor dissatisfied\",\n",
    "       \"I hate my job\",\n",
    "       \"Other (please specify)\"]\n",
    "\n",
    "mod =[\"Extremely dissatisfied\",\n",
    "      \"Other\",\n",
    "      \"Moderately satisfied\",\n",
    "      \"Slightly dissatisfied\",\n",
    "      \"Neither satisfied nor dissatisfied\",\n",
    "      \"Extremely dissatisfied\",\n",
    "      \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2016.job_satisfaction.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the dataframe for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2016.to_csv(mod_df+\"2016.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again check the dataframe to find dissimilarities and find a way to correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that could be helpfull in analyzing this dataset\n",
    "col_2017 = ['Professional','Country','EmploymentStatus',\n",
    "            'FormalEducation','CompanySize', 'CareerSatisfaction','JobSatisfaction',\n",
    "            'JobSecurity','Gender',\n",
    "            'Salary','ExpectedSalary']\n",
    "\n",
    "# reading data from CSV file\n",
    "df_2017 =  pd.read_csv(survey+'2017.csv.gz',usecols=col_2017, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I prefer not to say \",\"Moldavia \",\"Ireland \",\"Aland Islands \",\"New Caledonia (French) \",\"U.S. Minor Outlying Islands \",\"Polynesia (French) \",\"French Guyana \",\"Pitcairn Island \",\"Antigua and Barbuda \",\"Martinique (French) \",\"Heard and McDonald Islands \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2017.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissimilarities\n",
    "col = [\"I prefer not to say\",\"Moldavia\",\"Ireland\",\"Aland Islands\",\n",
    "       \"New Caledonia (French)\",\"U.S. Minor Outlying Islands\",\n",
    "       \"Polynesia (French)\",\"French Guyana\",\"Pitcairn Island\",\"Antigua and Barbuda\",\n",
    "       \"Martinique (French)\",\"Macau\",\"Heard and McDonald Islands\"] # Columns have naming difference\n",
    "\n",
    "# Modification\n",
    "mod =[\"Other\",\"Moldova\",\"Ireland {Republic}\",\"Åland Islands\",\"New Caledonia\",\n",
    "      \"United States Minor Outlying Islands\",\"French Polynesia\",\"Guyana\",\n",
    "      \"Pitcairn\",\"Antigua & Deps\",\"Martinique\",\"Macau\",\"Heard and Island and McDonald Islands\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2017.replace(to_replace=col[i], value=mod[i], inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check country and add subregion and continent to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2017['Country'].isnull()\n",
    "\n",
    "for i in range(df_2017.shape[0]):\n",
    "    x = df_2017.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2017.shape[0]:\n",
    "    df_2017['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2017.shape[0]:\n",
    "        df_2017['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company size\n",
    "Changing company size to be consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not employed, and not looking for work', 'Employed part-time',\n",
       "       'Employed full-time',\n",
       "       'Independent contractor, freelancer, or self-employed',\n",
       "       'Not employed, but looking for work', 'Other', 'Retired'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017['EmploymentStatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column values\n",
    "col = [\"20 to 99 employees\",\"10,000 or more employees\",\"10 to 19 employees\",\n",
    "       \"Fewer than 10 employees\",\"5,000 to 9,999 employees\",\"100 to 499 employees\",\n",
    "       \"1,000 to 4,999 employees\",\"500 to 999 employees\",\n",
    "       \"I don't know\",\"I prefer not to answer\",\"Brunei\"] #Changing thses to new one\n",
    "\n",
    "# Modified values\n",
    "mod = [\"20-99\",\"10000+\",\"10-19\",\"<10\",\"5000-9999\",\n",
    "       \"100-499\",\"1000-5000\",\"500-1000\",\n",
    "       \"I don't know\",\"I prefer not to answer\",\"nan\"]\n",
    "\n",
    "# Replace them with new values\n",
    "for i in range(len(col)):\n",
    "    df_2017.CompanySize.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '20-99', '10000+', '10-19', '<10', '5000-9999', '100-499',\n",
       "       '1000-5000', '500-1000', \"I don't know\", 'I prefer not to answer',\n",
       "       'nan'], dtype=object)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.CompanySize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Professional', 'Country', 'EmploymentStatus', 'FormalEducation',\n",
       "       'CompanySize', 'CareerSatisfaction', 'JobSatisfaction', 'JobSecurity',\n",
       "       'Gender', 'Salary', 'ExpectedSalary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "In this survey questionier was asked to answer with number between 0 to 10. Changing this evaluation with values as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [i for i in range(11)]\n",
    "\n",
    "mod =[\"Extremely dissatisfied\",\"Extremely dissatisfied\",\n",
    "      \"Moderately dissatisfied\",\"Moderately dissatisfied\",\n",
    "      \"Neither satisfied nor dissatisfied\",\"Neither satisfied nor dissatisfied\",\n",
    "      \"Slightly satisfied\",\n",
    "      \"Moderately satisfied\",\"Moderately satisfied\",\n",
    "      \"Extremely satisfied\",\"Extremely satisfied\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2017.JobSatisfaction.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slary Range\n",
    "In 2017 survey results the values are numeric and there is no range. So we add 'Salary_range' column to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column\n",
    "df_2017['Salary_range']=np.nan\n",
    "\n",
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "# using the following dictionary to replace values\n",
    "dic = {40000:\"$40,000 - $50,000\",\n",
    "        200000:\"More than $200,000\",\n",
    "        10000:\"$10,000 - $20,000\",\n",
    "        90000:\"$90,000 - $100,000\",\n",
    "        30000:\"$30,000 - $40,000\",\n",
    "        20000:\"$20,000 - $30,000\",\n",
    "        70000:\"$70,000 - $80,000\",\n",
    "        80000:\"$80,000 - $90,000\",\n",
    "        50000:\"$50,000 - $60,000\",\n",
    "        60000:\"$60,000 - $70,000\",\n",
    "        140000:\"$140,000 - $150,000\",\n",
    "        130000:\"$130,000 - $140,000\",\n",
    "        100000:\"$100,000 - $110,000\",\n",
    "        110000:\"$110,000 - $120,000\",\n",
    "        160000:\"$160,000 - $170,000\",\n",
    "        180000:\"$180,000 - $190,000\",\n",
    "        120000:\"$120,000 - $130,000\",\n",
    "        150000:\"$150,000 - $160,000\",\n",
    "        190000:\"$190,000 - $200,000\",\n",
    "        170000:\"$170,000 - $180,000\"}\n",
    "\n",
    "# for less than $10,000 salary\n",
    "index = df_2017.Salary[df_2017.Salary < 10000.0].index\n",
    "df_2017.loc[index,'Salary_range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    index = df_2017.Salary[(df_2017['Salary'] >= salary) & (df_2017['Salary'] < salary+step)].index\n",
    "    df_2017.loc[index,'Salary_range']= dic[salary]\n",
    "    salary+=step\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35935"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of null values\n",
    "np.sum(df_2017.Salary_range.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns **'Salary'** and **'ExpectedSalary'** in 2017 results data sets. There are cases which **'Salary'** is **nan** but there is value for expected salary. It's not bad idea to use that value as salary when its nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "\n",
    "df_temp = df_2017[(df_2017['ExpectedSalary'] != np.nan) & (df_2017['ExpectedSalary'] < 10000)]\n",
    "index = df_temp.Salary.isnull().index\n",
    "df_2017.loc[index,'Salary_range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    df_temp = df_2017[(df_2017['ExpectedSalary']  >= salary) & (df_2017['ExpectedSalary'] < salary+step)]\n",
    "    index   = df_temp.Salary.isnull().index\n",
    "    #print(index)\n",
    "    df_2017.loc[index,'Salary_range']= dic[salary]\n",
    "    salary+=step\n",
    "    \n",
    "    \n",
    "#df_2017.loc[index,'Salary_range']= 'Less than $10,000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35935"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of null values after considering ExpectedSalary\n",
    "np.sum(df_2017.Salary_range.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final step save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2017.to_csv(mod_df+\"2017.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,12,13,52,53,120,124) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# columns to be used for reding 2018 results \n",
    "col_2018 = ['Country','Employment','FormalEducation',\n",
    "            'CompanySize','JobSatisfaction','CareerSatisfaction',\n",
    "            'Salary','SalaryType','ConvertedSalary','Gender','Age']\n",
    "\n",
    "df_2018 = pd.read_csv(survey+\"2018.csv.gz\", usecols=col_2018, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Extremely satisfied', 'Moderately dissatisfied',\n",
       "       'Moderately satisfied', 'Neither satisfied nor dissatisfied',\n",
       "       'Slightly satisfied', nan, 'Slightly dissatisfied',\n",
       "       'Extremely dissatisfied'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.JobSatisfaction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and continent\n",
    "First thing first. Country and continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of... \",\"Other Country (Not Listed Above) \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2018.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is only two differences. lets solve them by replace command\n",
    "df_2018.Country.replace(\"Iran, Islamic Republic of...\", \"Iran\", inplace=True)\n",
    "df_2018.Country.replace(\"Other Country (Not Listed Above)\", \"Other\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding subregion and continent columns\n",
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2018['Country'].isnull()\n",
    "\n",
    "for i in range(df_2018.shape[0]):\n",
    "    x = df_2018.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2018.shape[0]:\n",
    "    df_2018['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2018.shape[0]:\n",
    "        df_2018['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company size\n",
    "Changing the company size values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"20 to 99 employees\",\"10,000 or more employees\",\"100 to 499 employees\",\n",
    "       \"10 to 19 employees\",\"500 to 999 employees\",\n",
    "       \"1,000 to 4,999 employees\",\"5,000 to 9,999 employees\",\n",
    "       \"Fewer than 10 employees\"]\n",
    "\n",
    "mod = [\"20-99\",\"10000+\",\"100-499\",\"10-19\",\"500-99\",\"1000-4999\",\"5000-9999\",\"<10\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2018.CompanySize.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender\n",
    "There are different selection for Gende for each column. For see the affect of Gender on job satisfaction we group them in three different cases: Male, Female, genderqueer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_2018[~df_2018['Gender'].isin(['Male', 'Female', np.nan])].index\n",
    "df_2018.loc[index, 'Gender'] = 'genderqueer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bachelor’s degree (BA, BS, B.Eng., etc.)', 'Associate degree',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Master’s degree (MA, MS, M.Eng., MBA, etc.)',\n",
       "       'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
       "       nan, 'Primary/elementary school',\n",
       "       'Professional degree (JD, MD, etc.)',\n",
       "       'I never completed any formal education',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.FormalEducation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_2016' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9b17ba3dc187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_2016\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFormalEducation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_2016' is not defined"
     ]
    }
   ],
   "source": [
    "df_2016.FormalEducation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50578\n",
      "47702\n",
      "ConvertedSalary: 98855\n",
      "ConvertedSalary: 7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98855"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(df_2018.Salary.notnull()==True))\n",
    "print(np.sum(df_2018.ConvertedSalary.notnull()==True))\n",
    "print(\"ConvertedSalary:\",len(df_2018.ConvertedSalary.isnull()))\n",
    "print(\"ConvertedSalary:\",len(df_2018.ConvertedSalary.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving 2018 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_2018 = pd.read_csv(\"./surveys_results/survey_results_public_\"+\"2018.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2018.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(df_2018.corr(), annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected columns to read from 2019 dataset\n",
    "col_2019 = ['Employment','Country','EdLevel','OrgSize','DevType','CareerSat','JobSat',\n",
    "            'CompTotal','CompFreq','ConvertedComp','Ethnicity','Gender']\n",
    "\n",
    "df_2019 = pd.read_csv(survey+\"2019.csv.gz\", usecols=col_2019, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if there are any dissimilarity between country and the refrence we have. then add continent and subregion columns to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2019.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Slightly satisfied', 'Slightly dissatisfied',\n",
       "       'Neither satisfied nor dissatisfied', 'Very satisfied',\n",
       "       'Very dissatisfied'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.JobSat.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is just one case and we replace it we 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.Country.replace('Other Country (Not Listed Above)', 'Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding subregion and continent columns\n",
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2019['Country'].isnull()\n",
    "\n",
    "for i in range(df_2019.shape[0]):\n",
    "    x = df_2019.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2019.shape[0]:\n",
    "    df_2019['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2019.shape[0]:\n",
    "        df_2019['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected columns to read from 2020 dataset\n",
    "col_2020 = ['Age','CompTotal','ConvertedComp','Country',\n",
    "            'EdLevel','Employment','Gender',\n",
    "            'JobSat','Sexuality','Trans']\n",
    "\n",
    "df_2020 = pd.read_csv(survey+\"2020.csv.gz\", usecols=col_2020, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([          nan, 1.1600000e+05, 2.5000000e+04, ..., 1.2775000e+07,\n",
       "       2.7170564e+07, 4.3100000e+06])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.CompTotal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29705"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_2020['ConvertedComp'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
