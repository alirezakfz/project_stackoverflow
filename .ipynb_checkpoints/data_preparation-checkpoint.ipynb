{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation of Stackoverflow surveys results to analyse develpoer job satisfaction\n",
    "\n",
    "This notebook looks at stackoverflow surveys duriring six years from 2015 to 2020 with the aim to realize general job satisfaction of developers according to the surveys [here](https://insights.stackoverflow.com/survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "survey = \"./surveys_results/survey_results_public_\"\n",
    "mod_df = \"./modified_results/modified_survey_results_public_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 surveys results stored as CSV format in \"surveys_results\" folder. Each year there are differnces in questionier asked from IT persons/Develpoers to answer them. But there are some questions repeated in each year. Our focus is to use fields in the results that belong to such questions like country of residence or salary.\n",
    "First we look to country of residence from the 2015 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading country results from 2016 and 2015\n",
    "df_2015 = pd.read_csv(survey+\"2015.csv.gz\", usecols=['Country'], skiprows=1, compression='gzip') #2015 country results\n",
    "\n",
    "df_2018 = pd.read_csv(survey+\"2018.csv.gz\", usecols=['Country'], compression='gzip') #2016 country results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look to number of unique countries in these two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of 2015: 157\n",
      "Lenght of 2018: 181\n"
     ]
    }
   ],
   "source": [
    "# 2015 unique countries\n",
    "print(\"Lenght of 2015:\", len(df_2015.Country.unique()))\n",
    "print(\"Lenght of 2018:\", len(df_2018.Country.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different number of ccountries in each dataframe. Also there are some countries which have different naming in each one of these surveys. For example 'Viet Nam' in 2018 and 'Vietnam' in 2015 or 'Syria' in 2015 and 'Syrian Arab Republic' in 2018. Also there is 'un_subregion' column in 2016 results which not exist in other results. For this reason we have to modify columns values to have same value names and later we can categorize them like having **continent** or **subregion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of... , Hong Kong , Other Country (Not Listed Above) , Micronesia , Yemen , Fiji , Burundi , Lesotho , Marshall Islands , Malawi , Libya , Guinea , CÃ´te d'Ivoire , Central African Rep , Monaco , Gambia , Palau , Grenada , Belize , Suriname , East Timor , Dominica , Saint Lucia , Niger , Guyana , Nauru , Mali , Liberia , Cape Verde , Eritrea , Guinea-Bissau , "
     ]
    }
   ],
   "source": [
    "# example of dis-similarity between country names in data sets.\n",
    "unique_2018 =[]\n",
    "for x in df_2018.Country.unique():\n",
    "    unique_2018.append(x)\n",
    "\n",
    "unique_2015 =[]\n",
    "for x in df_2015.Country.unique():\n",
    "    unique_2015.append(x)\n",
    "    \n",
    "for x in unique_2018:\n",
    "    if x not in unique_2015:\n",
    "        print(x,', ',end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Removing dissimilarity among datasets\n",
    " \n",
    " Removing differences in country names. Adding 'un-subregion' and 'Continent' to data sets by creating new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be used for reding 2015 results \n",
    "col_2015=['Country','Age','Gender',\n",
    "          'Training & Education: BS in CS',\n",
    "          'Training & Education: No formal training',\n",
    "          'Training & Education: Some college, but no CS degree',\n",
    "          'Training & Education: Masters in CS',\n",
    "          'Training & Education: PhD in CS','Compensation',\n",
    "          'Employment Status','Job Satisfaction']\n",
    "\n",
    "# Reading selected columns\n",
    "df_2015 = pd.read_csv(\"./surveys_results/survey_results_public_\"+\"2015.csv.gz\", \n",
    "                      usecols=col_2015, skiprows=1, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find differnces in country names we check all the data sets with one unique list loaded from  **'country_continent.csv'** file. So we can add continent and subregion to data frame which miss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading list of countries and their properties\n",
    "df_country = pd.read_csv('./country_continent.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "uniques =[]\n",
    "for x in df_country.country.unique():\n",
    "    uniques.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which countries have different name from this list and modify them for 2015 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2015.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Prefer not to disclose', 'Female', nan, 'Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education\n",
    "In 2015 survey results university education level are separated in different cloumns. Lets create one column as **'FormalEducation'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_null_col = df_2015\n",
    "edu_col = ['Training & Education: BS in CS','Training & Education: No formal training',\n",
    "           'Training & Education: Some college, but no CS degree',\n",
    "           'Training & Education: Masters in CS',\n",
    "           'Training & Education: PhD in CS']\n",
    "\n",
    "# This dictionary used to make consistency between all survey results\n",
    "edu_value={'Training & Education: BS in CS':\"Bachelor's degree\",\n",
    "          'Training & Education: No formal training':\"No formal education\",\n",
    "          'Training & Education: Some college, but no CS degree':\"Some college/university study without earning a bachelor's degree\",\n",
    "          'Training & Education: Masters in CS':\"Master's degree\",\n",
    "          'Training & Education: PhD in CS':\"Doctoral degree\"}\n",
    "\n",
    "\n",
    "not_null_col = [] # store not null columns\n",
    "\n",
    "# creating new column as 'Formal_Education' education and updating it's value\n",
    "for col in edu_col:\n",
    "    not_null_col = df_2015[col][df_2015[col].notnull()==True].index\n",
    "    df_2015.loc[not_null_col,'Formal_Education']=edu_value[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Master degree (MA, MS, M.Eng., MBA, etc.)', nan,\n",
       "       'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
       "       'I never completed any formal education',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check FormalEducation column\n",
    "df_2015['Formal_Education'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the other 5 columns by having new **'FormalEducation'** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping education columns\n",
    "df_2015.drop(columns=edu_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting N/A value of country to nan\n",
    "#df_2015.loc[df_2015['Country']=='N/A', 'Country']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_2015['Country'].isnull()==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continent and subregion\n",
    "Adding **'un_subregion'** and **'Continent'** columns for further comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2015['Country'].isnull()\n",
    "\n",
    "for i in range(df_2015.shape[0]):\n",
    "    x = df_2015.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2015.shape[0]:\n",
    "    df_2015['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2015.shape[0]:\n",
    "        df_2015['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender\n",
    "To check the relation between gender and job satisfaction we categorize them in main 3 different categories: Male, Female and genderqueer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Prefer not to disclose', 'Female', nan, 'Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique values in 2015 survey for gender is as follow\n",
    "df_2015.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'Other' to 'genderqueer' to make consistency\n",
    "df_2015.Gender.replace('Other', 'genderqueer', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status\n",
    "For consistency between all other surveys we need to replace following values to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values in the 'Employment Status' which will be replaced by other values\n",
    "col = [\"I'm a student\",\"Prefer not to disclose\"]\n",
    "\n",
    "# Modified values \n",
    "mod = [\"Student\", \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2015['Employment Status'].replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "To make answers be consistent between all the surveys, replace the values in job satisfaction column as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"I'm somewhat satisfied with my job\",\n",
    "       \"I'm neither satisfied nor dissatisfied with my job\",\n",
    "       \"I love my job\",\n",
    "       \"I'm somewhat dissatisfied with my job\",\n",
    "       \"I hate my job\",\n",
    "       \"Other (please specify)\"]\n",
    "\n",
    "mod = [\"Moderately satisfied\",\n",
    "       \"Neither satisfied nor dissatisfied\",\n",
    "       \"Extremely satisfied\",\n",
    "       \"Slightly dissatisfied\",\n",
    "       \"Extremely dissatisfied\",\n",
    "       \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2015['Job Satisfaction'].replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Age', 'Gender', 'Compensation', 'Employment Status',\n",
       "       'Job Satisfaction', 'Formal_Education', 'UN_subregion', 'Continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015.rename(columns={'Age':'Age_Range', \n",
    "                        'Compensation':'Salary_Range',\n",
    "                        'Employment Status':'Employment_Status', \n",
    "                        'Job Satisfaction':'Job_Satisfaction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last thing : saving new dataframe df_2015 for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2015.to_csv(mod_df+\"2015.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataframe\n",
    "col_2016=['country','un_subregion','age_range','gender',\n",
    "          'salary_range','employment_status',\n",
    "          'company_size_range','job_satisfaction','education']\n",
    "\n",
    "df_2016 =  pd.read_csv(survey+'2016.csv.gz',usecols=col_2016, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and Continent\n",
    "First we make the country become same with our refrence also adding 'Continent' column to dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other (please specify) \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2016.country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one difference **'Other (please specify)'**. If any cell value in country column  **'un_subregion'**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding index of the rows with 'Other (please specify)'\n",
    "index = df_2016[df_2016['country']=='Other (please specify)'].index\n",
    "\n",
    "# changing their value to 'Other'\n",
    "df_2016.loc[index,'country'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2016['country'].isnull()\n",
    "\n",
    "for i in range(df_2016.shape[0]):\n",
    "    x = df_2016.iloc[i]['country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2016.shape[0]:\n",
    "    df_2016['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2016.shape[0]:\n",
    "        df_2016['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If continent and subregion added as without any problem we drop old un_subregion column\n",
    "df_2016.drop(columns=['un_subregion'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment status\n",
    "There is only one difference between 2015 and 2016 employment status and it's the 'Other' and 'Other (please specify)'. Lets make it be 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for employment status make consistency between their values\n",
    "df_2016.employment_status.loc[df_2016.employment_status=='Other (please specify)'] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal Education\n",
    "In 2016 results the field of education have multiple decisions as string in each row. We need to make a new 'FormalEducation' column with selected option from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm self-taught; On-the-job training; B.S. in Computer Science (or related field)\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of concatanated example\n",
    "df_2016.education[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all unique education strings from the dataframe\n",
    "edu_strings = df_2016.education.unique()\n",
    "\n",
    "# separate strings found by split function\n",
    "splited_list = []\n",
    "\n",
    "for edu in edu_strings:\n",
    "    if type(edu) != int and type(edu) != float:\n",
    "        for x in edu.split('; '):\n",
    "            if x not in splited_list:\n",
    "                splited_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm self-taught\",\n",
       " 'On-the-job training',\n",
       " 'B.S. in Computer Science (or related field)',\n",
       " 'Online class (e.g. Coursera, Codecademy, Khan Academy, etc.)',\n",
       " 'B.A. in Computer Science (or related field)',\n",
       " 'Masters Degree in Computer Science (or related field)',\n",
       " 'Some college coursework in Computer Science (or related field)',\n",
       " 'Full-time, intensive program (e.g. \"boot-camp\")',\n",
       " 'Industry certification program',\n",
       " 'PhD in Computer Science (or related field)',\n",
       " 'Part-time program (e.g. night school)',\n",
       " 'Mentorship program (e.g. Flatiron School, GDI, etc.)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Founded unique strings\n",
    "splited_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wee need to check each column and put the match into 'FormalEducation' list to be similar to 2015 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Master degree (MA, MS, M.Eng., MBA, etc.)', nan,\n",
       "       'Bachelor degree (BA, BS, B.Eng., etc.)',\n",
       "       'I never completed any formal education',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values in 2015 for fomal education\n",
    "df_2015.Formal_Education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column succesfully added\n"
     ]
    }
   ],
   "source": [
    "# dictionary for equivalent string\n",
    "edu_dic={\"I'm self-taught\": 'No formal education',\n",
    "        'B.S. in Computer Science (or related field)':\"Bachelor's degree\",\n",
    "        'B.A. in Computer Science (or related field)':\"Bachelor's degree\",\n",
    "        'Masters Degree in Computer Science (or related field)':\"Master's degree\",\n",
    "        'PhD in Computer Science (or related field)':\"Doctoral degree\"}\n",
    "\n",
    "\n",
    "\n",
    "# check if key exist in a dictionary or not\n",
    "def checkKey(dict, key):\n",
    "    if key in dict.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# finding equivalent degree for each syrvey result\n",
    "formal_edu=[]\n",
    "for edu_str in df_2016.education:\n",
    "    if type(edu_str) != int and type(edu_str) != float:\n",
    "        edu_list = edu_str.split('; ')\n",
    "        check = True\n",
    "        value=''\n",
    "        for x in edu_list:\n",
    "            if checkKey(edu_dic, x) and check:\n",
    "                check=False\n",
    "                value=edu_dic[x]\n",
    "        if check:\n",
    "            formal_edu.append('No formal education')\n",
    "        else:\n",
    "            formal_edu.append(value)\n",
    "    else:\n",
    "        formal_edu.append(np.nan)\n",
    "\n",
    "# Adding new column as 'FormalEducation' to dataframe\n",
    "if len(formal_edu) == df_2016.shape[0]:\n",
    "    df_2016['Formal_Education'] = formal_edu\n",
    "    print('New column succesfully added')\n",
    "else:\n",
    "    print('error: size mismatch to add new column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Size\n",
    "Now we check the company size values and make it consistent to what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '100-499 employees', 'I am not part of a company',\n",
       "       '10-19 employees', '5-9 employees', '20-99 employees',\n",
       "       '1-4 employees', '500-999 employees', '1,000-4,999 employees',\n",
       "       '10,000+ employees', '5,000-9,999 employees', 'I am not sure',\n",
       "       'Other (please specify)'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.company_size_range.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column values\n",
    "col = [\"100-499 employees\",\"I am not part of a company\",\"10-19 employees\",\n",
    "       \"5-9 employees\",\"20-99 employees\",\"1-4 employees\",\n",
    "       \"500-999 employees\",\"1,000-4,999 employees\",\"10,000+ employees\",\n",
    "       \"5,000-9,999 employees\",\"I am not sure\",\"Other (please specify)\"] #Changing thses to new one\n",
    "\n",
    "# Modified values\n",
    "mod = [\"100-499\",\"I am not part of a company\",\n",
    "       \"10-19\",\"<10\",\"20-99\",\"<10\",\"500-999\",\n",
    "       \"1000-4999\",\"10000+\",\"5000-9999\",\"I am not sure\",\n",
    "       \"I prefer not to answer\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2016.company_size_range.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Age_Range', 'Gender', 'Salary_Range', 'Employment_Status',\n",
       "       'Job_Satisfaction', 'Formal_Education', 'UN_subregion', 'Continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.salary_range.unique()\n",
    "df_2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.salary_range.replace('Other (please specify)','Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "Change the values of job satisfaction column for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"I love my job\",\n",
    "       \"I don't have a job\",\n",
    "       \"I'm somewhat satisfied with my job\",\n",
    "       \"I'm somewhat dissatisfied with my job\",\n",
    "       \"I'm neither satisfied nor dissatisfied\",\n",
    "       \"I hate my job\",\n",
    "       \"Other (please specify)\"]\n",
    "\n",
    "mod =[\"Extremely dissatisfied\",\n",
    "      \"Other\",\n",
    "      \"Moderately satisfied\",\n",
    "      \"Slightly dissatisfied\",\n",
    "      \"Neither satisfied nor dissatisfied\",\n",
    "      \"Extremely dissatisfied\",\n",
    "      \"Other\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2016.job_satisfaction.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming and dropping unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'age_range', 'gender', 'salary_range', 'employment_status',\n",
       "       'company_size_range', 'job_satisfaction', 'education', 'UN_subregion',\n",
       "       'Continent', 'Formal_Education'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.rename(columns={'country':'Country',\n",
    "                       'age_range':'Age_Range',\n",
    "                       'gender':'Gender',\n",
    "                       'salary_range':'Salary_Range',\n",
    "                       'employment_status':'Employment_Status',\n",
    "                       'company_size_range':'Company_Size',\n",
    "                       'job_satisfaction':'Job_Satisfaction'},\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.drop(columns=['education'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the dataframe for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2016.to_csv(mod_df+\"2016.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again check the dataframe to find dissimilarities and find a way to correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that could be helpfull in analyzing this dataset\n",
    "col_2017 = ['Country','EmploymentStatus','FormalEducation','CompanySize', \n",
    "            'CareerSatisfaction','JobSatisfaction','Gender',\n",
    "            'Salary','ExpectedSalary']\n",
    "\n",
    "# reading data from CSV file\n",
    "df_2017 =  pd.read_csv(survey+'2017.csv.gz',usecols=col_2017, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I prefer not to say \",\"Moldavia \",\"Ireland \",\"Aland Islands \",\"New Caledonia (French) \",\"U.S. Minor Outlying Islands \",\"Polynesia (French) \",\"French Guyana \",\"Pitcairn Island \",\"Antigua and Barbuda \",\"Martinique (French) \",\"Heard and McDonald Islands \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2017.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissimilarities\n",
    "col = [\"I prefer not to say\",\"Moldavia\",\"Ireland\",\"Aland Islands\",\n",
    "       \"New Caledonia (French)\",\"U.S. Minor Outlying Islands\",\n",
    "       \"Polynesia (French)\",\"French Guyana\",\"Pitcairn Island\",\"Antigua and Barbuda\",\n",
    "       \"Martinique (French)\",\"Macau\",\"Heard and McDonald Islands\"] # Columns have naming difference\n",
    "\n",
    "# Modification\n",
    "mod =[\"Other\",\"Moldova\",\"Ireland {Republic}\",\"Ãland Islands\",\"New Caledonia\",\n",
    "      \"United States Minor Outlying Islands\",\"French Polynesia\",\"Guyana\",\n",
    "      \"Pitcairn\",\"Antigua & Deps\",\"Martinique\",\"Macau\",\"Heard and Island and McDonald Islands\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2017.replace(to_replace=col[i], value=mod[i], inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check country and add subregion and continent to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2017['Country'].isnull()\n",
    "\n",
    "for i in range(df_2017.shape[0]):\n",
    "    x = df_2017.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2017.shape[0]:\n",
    "    df_2017['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2017.shape[0]:\n",
    "        df_2017['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Male', 'Female', 'Gender non-conforming', 'Other', 'Transgender']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all unique education strings from the dataframe\n",
    "gender_strings = df_2017.Gender.unique()\n",
    "\n",
    "# separate strings found by split function\n",
    "splited_list = []\n",
    "\n",
    "for g in gender_strings:\n",
    "    if type(g) != int and type(g) != float:\n",
    "        for x in g.split('; '):\n",
    "            if x not in splited_list:\n",
    "                splited_list.append(x)\n",
    "splited_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Gender non-conforming' and 'Transgender' with 'genderqueer'\n",
    "index = df_2017[(df_2017.Gender != 'Male') &\n",
    "                (df_2017.Gender != 'Female') &\n",
    "                (df_2017.Gender != 'Other') &\n",
    "               (df_2017.Gender != np.nan)].index\n",
    "\n",
    "df_2017.loc[index, 'Gender'] = 'genderqueer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company size\n",
    "Changing company size to be consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '20 to 99 employees', '10,000 or more employees',\n",
       "       '10 to 19 employees', 'Fewer than 10 employees',\n",
       "       '5,000 to 9,999 employees', '100 to 499 employees',\n",
       "       '1,000 to 4,999 employees', '500 to 999 employees', \"I don't know\",\n",
       "       'I prefer not to answer', 'Brunei'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017['CompanySize'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column values\n",
    "col = [\"20 to 99 employees\",\"10,000 or more employees\",\"10 to 19 employees\",\n",
    "       \"Fewer than 10 employees\",\"5,000 to 9,999 employees\",\"100 to 499 employees\",\n",
    "       \"1,000 to 4,999 employees\",\"500 to 999 employees\",\n",
    "       \"I don't know\",\"I prefer not to answer\",\"Brunei\"] #Changing thses to new one\n",
    "\n",
    "# Modified values\n",
    "mod = [\"20-99\",\"10000+\",\"10-19\",\"<10\",\"5000-9999\",\n",
    "       \"100-499\",\"1000-4999\",\"500-999\",\n",
    "       \"I don't know\",\"I prefer not to answer\",\"nan\"]\n",
    "\n",
    "# Replace them with new values\n",
    "for i in range(len(col)):\n",
    "    df_2017.CompanySize.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '20-99', '10000+', '10-19', '<10', '5000-9999', '100-499',\n",
       "       '1000-4999', '500-999', \"I don't know\", 'I prefer not to answer',\n",
       "       'nan'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new Values\n",
    "df_2017.CompanySize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job satisfaction\n",
    "In this survey questionier was asked to answer with number between 0 to 10. Changing this evaluation with values as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [i for i in range(11)]\n",
    "\n",
    "mod =[\"Extremely dissatisfied\",\"Extremely dissatisfied\",\n",
    "      \"Moderately dissatisfied\",\"Moderately dissatisfied\",\n",
    "      \"Neither satisfied nor dissatisfied\",\"Neither satisfied nor dissatisfied\",\n",
    "      \"Slightly satisfied\",\n",
    "      \"Moderately satisfied\",\"Moderately satisfied\",\n",
    "      \"Extremely satisfied\",\"Extremely satisfied\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2017.JobSatisfaction.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slary Range\n",
    "In 2017 survey results the values are numeric and there is no range. So we add 'Salary_range' column to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column\n",
    "df_2017['Salary_Range']=np.nan\n",
    "\n",
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "# using the following dictionary to replace values\n",
    "dic = {40000:\"$40,000 - $50,000\",\n",
    "        200000:\"More than $200,000\",\n",
    "        10000:\"$10,000 - $20,000\",\n",
    "        90000:\"$90,000 - $100,000\",\n",
    "        30000:\"$30,000 - $40,000\",\n",
    "        20000:\"$20,000 - $30,000\",\n",
    "        70000:\"$70,000 - $80,000\",\n",
    "        80000:\"$80,000 - $90,000\",\n",
    "        50000:\"$50,000 - $60,000\",\n",
    "        60000:\"$60,000 - $70,000\",\n",
    "        140000:\"$140,000 - $150,000\",\n",
    "        130000:\"$130,000 - $140,000\",\n",
    "        100000:\"$100,000 - $110,000\",\n",
    "        110000:\"$110,000 - $120,000\",\n",
    "        160000:\"$160,000 - $170,000\",\n",
    "        180000:\"$180,000 - $190,000\",\n",
    "        120000:\"$120,000 - $130,000\",\n",
    "        150000:\"$150,000 - $160,000\",\n",
    "        190000:\"$190,000 - $200,000\",\n",
    "        170000:\"$170,000 - $180,000\"}\n",
    "\n",
    "# for less than $10,000 salary\n",
    "index = df_2017.Salary[df_2017.Salary < 10000.0].index\n",
    "df_2017.loc[index,'Salary_Range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    index = df_2017.Salary[(df_2017['Salary'] >= salary) & (df_2017['Salary'] < salary+step)].index\n",
    "    df_2017.loc[index,'Salary_Range']= dic[salary]\n",
    "    salary+=step\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38501"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of null values\n",
    "np.sum(df_2017.Salary_Range.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns **'Salary'** and **'ExpectedSalary'** in 2017 results data sets. There are cases which **'Salary'** is **nan** but there is value for expected salary. It's not bad idea to use that value as salary when its nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "\n",
    "df_temp = df_2017[(df_2017['ExpectedSalary'] != np.nan) & (df_2017['ExpectedSalary'] < 10000)]\n",
    "index = df_temp.Salary.isnull().index\n",
    "df_2017.loc[index,'Salary_Range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    df_temp = df_2017[(df_2017['ExpectedSalary']  >= salary) & (df_2017['ExpectedSalary'] < salary+step)]\n",
    "    index   = df_temp.Salary.isnull().index\n",
    "    #print(index)\n",
    "    df_2017.loc[index,'Salary_Range']= dic[salary]\n",
    "    salary+=step\n",
    "    \n",
    "    \n",
    "#df_2017.loc[index,'Salary_range']= 'Less than $10,000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35935"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of null values after considering ExpectedSalary\n",
    "np.sum(df_2017.Salary_Range.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Secondary school',\n",
       "       \"Some college/university study without earning a bachelor's degree\",\n",
       "       \"Bachelor's degree\", 'Doctoral degree', \"Master's degree\",\n",
       "       'Professional degree', 'Primary/elementary school',\n",
       "       'I prefer not to answer', 'I never completed any formal education'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.FormalEducation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'EmploymentStatus', 'FormalEducation', 'CompanySize',\n",
       "       'CareerSatisfaction', 'JobSatisfaction', 'Gender', 'Salary',\n",
       "       'ExpectedSalary', 'UN_subregion', 'Continent', 'Salary_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.rename(columns={'EmploymentStatus':'Employment_Status',\n",
    "                       'FormalEducation':'Formal_Education',\n",
    "                       'CompanySize':'Company_Size',\n",
    "                       'JobSatisfaction':'Job_Satisfaction'},\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.drop(columns=['ExpectedSalary'], inplace=True) #'CareerSatisfaction','Salary',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final step save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving prepared dataframe into new CSV file\n",
    "df_2017.to_csv(mod_df+\"2017.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,12,13,52,53,120,124) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# columns to be used for reding 2018 results \n",
    "col_2018 = ['Country','Employment','FormalEducation',\n",
    "            'CompanySize','JobSatisfaction','CareerSatisfaction',\n",
    "            'Salary','SalaryType','ConvertedSalary','Gender','Age']\n",
    "\n",
    "df_2018 = pd.read_csv(survey+\"2018.csv.gz\", usecols=col_2018, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51153"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_2018.ConvertedSalary.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and continent\n",
    "First thing first. Country and continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of... \",\"Other Country (Not Listed Above) \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2018.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is only two differences. lets solve them by replace command\n",
    "df_2018.Country.replace(\"Iran, Islamic Republic of...\", \"Iran\", inplace=True)\n",
    "df_2018.Country.replace(\"Other Country (Not Listed Above)\", \"Other\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding subregion and continent columns\n",
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2018['Country'].isnull()\n",
    "\n",
    "for i in range(df_2018.shape[0]):\n",
    "    x = df_2018.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2018.shape[0]:\n",
    "    df_2018['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2018.shape[0]:\n",
    "        df_2018['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company size\n",
    "Changing the company size values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"20 to 99 employees\",\"10,000 or more employees\",\"100 to 499 employees\",\n",
    "       \"10 to 19 employees\",\"500 to 999 employees\",\n",
    "       \"1,000 to 4,999 employees\",\"5,000 to 9,999 employees\",\n",
    "       \"Fewer than 10 employees\"]\n",
    "\n",
    "mod = [\"20-99\",\"10000+\",\"100-499\",\"10-19\",\"500-999\",\"1000-4999\",\"5000-9999\",\"<10\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2018.CompanySize.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender\n",
    "There are different selection for Gende for each column. For see the affect of Gender on job satisfaction we group them in three different cases: Male, Female, genderqueer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', nan, 'Female',\n",
       "       'Female;Male;Transgender;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Female;Male',\n",
       "       'Male;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Non-binary, genderqueer, or gender non-conforming', 'Transgender',\n",
       "       'Female;Transgender',\n",
       "       'Transgender;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Female;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Female;Transgender;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Male;Transgender', 'Female;Male;Transgender',\n",
       "       'Female;Male;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Male;Transgender;Non-binary, genderqueer, or gender non-conforming'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it consistent with other surveys we just limit gender to three categories: Male, Female, genderqueer\n",
    "# replacing non-binary values with genderqueer \n",
    "index = df_2018[~df_2018['Gender'].isin(['Male', 'Female', np.nan])].index\n",
    "df_2018.loc[index, 'Gender'] = 'genderqueer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary range\n",
    "Adding new column **'Salary_range'** to make consistency between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In 2018 survey results the values are numeric and there is no range. So we add 'Salary_range' column to it.\n",
    "\n",
    "# Adding the column\n",
    "df_2018['Salary_Range']=np.nan\n",
    "\n",
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "# using the following dictionary to replace values\n",
    "dic = {40000:\"$40,000 - $50,000\",\n",
    "        200000:\"More than $200,000\",\n",
    "        10000:\"$10,000 - $20,000\",\n",
    "        90000:\"$90,000 - $100,000\",\n",
    "        30000:\"$30,000 - $40,000\",\n",
    "        20000:\"$20,000 - $30,000\",\n",
    "        70000:\"$70,000 - $80,000\",\n",
    "        80000:\"$80,000 - $90,000\",\n",
    "        50000:\"$50,000 - $60,000\",\n",
    "        60000:\"$60,000 - $70,000\",\n",
    "        140000:\"$140,000 - $150,000\",\n",
    "        130000:\"$130,000 - $140,000\",\n",
    "        100000:\"$100,000 - $110,000\",\n",
    "        110000:\"$110,000 - $120,000\",\n",
    "        160000:\"$160,000 - $170,000\",\n",
    "        180000:\"$180,000 - $190,000\",\n",
    "        120000:\"$120,000 - $130,000\",\n",
    "        150000:\"$150,000 - $160,000\",\n",
    "        190000:\"$190,000 - $200,000\",\n",
    "        170000:\"$170,000 - $180,000\"}\n",
    "\n",
    "# for less than $10,000 salary\n",
    "index = df_2018.ConvertedSalary[(df_2018['ConvertedSalary'] < 10000.0) & (df_2018['ConvertedSalary'] != np.nan)].index\n",
    "df_2018.loc[index,'Salary_Range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    index = df_2018.ConvertedSalary[(df_2018['ConvertedSalary'] >= salary) & (df_2018['ConvertedSalary'] < salary+step)].index\n",
    "    df_2018.loc[index,'Salary_Range']= dic[salary]\n",
    "    salary+=step\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal Education\n",
    "To make consistency between values we replace (Rename) the values in dataframe as follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Bachelorâs degree (BA, BS, B.Eng., etc.)\",\n",
    "       \"Associate degree\",\n",
    "       \"Some college/university study without earning a degree\",\n",
    "       \"Masterâs degree (MA, MS, M.Eng., MBA, etc.)\",\n",
    "       \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\",\n",
    "       \"Primary/elementary school\",\"Professional degree (JD, MD, etc.)\",\n",
    "       \"I never completed any formal education\",\n",
    "       \"Other doctoral degree (Ph.D, Ed.D., etc.)\"]\n",
    "\n",
    "mod = [\"Bachelor's degree\",\n",
    "       \"Associate degree\",\n",
    "       \"Some college/university study without earning a bachelor's degree\",\n",
    "       \"Master's degree\",\n",
    "       \"Secondary school\",\n",
    "       \"Primary/elementary school\",\n",
    "       \"Professional degree\",\n",
    "       \"No formal education\",\n",
    "       \"Doctoral degree\"]\n",
    "\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2018.FormalEducation.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Employed part-time\",\"Employed full-time\",\n",
    "       \"Independent contractor, freelancer, or self-employed,\",\n",
    "       \"Not employed, and not looking for work,\",\n",
    "       \"Not employed, but looking for work\",\"Retired\"]\n",
    "\n",
    "mod = [\"Employed part-time\",\"Employed full-time\",\n",
    "       \"Freelance / Contractor\",\"Unemployed\",\n",
    "       \"Unemployed, looking for work\",\"Retired\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2018.FormalEducation.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming columns and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Employment', 'FormalEducation', 'CompanySize',\n",
       "       'JobSatisfaction', 'CareerSatisfaction', 'Salary', 'SalaryType',\n",
       "       'ConvertedSalary', 'Gender', 'Age', 'UN_subregion', 'Continent',\n",
       "       'Salary_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.rename(columns={'Age':'Age_Range', 'FormalEducation':'Formal_Education',\n",
    "                        'CompanySize':'Company_Size', \n",
    "                        'Employment':'Employment_Status',\n",
    "                        'JobSatisfaction':'Job_Satisfaction',\n",
    "                       'CareerSatisfaction':'Career_Satisfaction'},\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.drop(columns=['Salary','SalaryType','ConvertedSalary'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving 2018 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018.to_csv(mod_df+\"2018.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2018.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(df_2018.corr(), annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected columns to read from 2019 dataset\n",
    "col_2019 = ['Employment','Country','EdLevel','OrgSize','CareerSat','JobSat','ConvertedComp','Gender']\n",
    "\n",
    "df_2019 = pd.read_csv(survey+\"2019.csv.gz\", usecols=col_2019, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if there are any dissimilarity between country and the refrence we have. then add continent and subregion columns to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Country (Not Listed Above) \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2019.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    nan,   8820.,  61000., ...,  38766.,  13272., 588012.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.ConvertedComp.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and Continent\n",
    "There is just one case and we replace it we 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.Country.replace('Other Country (Not Listed Above)', 'Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding subregion and continent columns\n",
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2019['Country'].isnull()\n",
    "\n",
    "for i in range(df_2019.shape[0]):\n",
    "    x = df_2019.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2019.shape[0]:\n",
    "    df_2019['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2019.shape[0]:\n",
    "        df_2019['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal Education\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019['Formal_Education'] = df_2019['EdLevel']\n",
    "\n",
    "col = [\"Primary/elementary school\",\n",
    "       \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\",\n",
    "       \"Bachelorâs degree (BA, BS, B.Eng., etc.)\",\n",
    "       \"Some college/university study without earning a degree\",\n",
    "       \"Masterâs degree (MA, MS, M.Eng., MBA, etc.)\",\n",
    "       \"Other doctoral degree (Ph.D, Ed.D., etc.)\",\n",
    "       \"Associate degree\",\n",
    "       \"Professional degree (JD, MD, etc.)\",\n",
    "       \"I never completed any formal education\"]\n",
    "\n",
    "mod =[\"Primary/elementary school\",\n",
    "      \"Secondary school\",\n",
    "      \"Bachelor's degree\",\n",
    "      \"Some college/university study without earning a bachelor's degree\",\n",
    "      \"Master's degree\",\n",
    "      \"Doctoral degree\",\n",
    "      \"Associate degree\",\n",
    "      \"Professional degree\",\n",
    "      \"No formal education\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2019.Formal_Education.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emplyment Status 'Employment' colum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Not employed, and not looking for work\",\n",
    "       \"Not employed, but looking for work\",\"Employed full-time\",\n",
    "       \"Independent contractor, freelancer, or self-employed\",\n",
    "       \"Employed part-time\",\"Retired\"]\n",
    "\n",
    "mod = [\"Unemployed\",\"Unemployed, looking for work\",\"Employed full-time\",\n",
    "       \"Freelance / Contractor\",\n",
    "       \"Employed part-time\",\"Retired\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2019.Formal_Education.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary\n",
    "In 2019 survey results there is column as 'ConvertedComp' that asked persons to enter their total salary as dollor. We use that column for creating **'Salary_range'** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column\n",
    "df_2019['Salary_Range']=np.nan\n",
    "\n",
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "# using the following dictionary to replace values\n",
    "dic = {40000:\"$40,000 - $50,000\",\n",
    "        200000:\"More than $200,000\",\n",
    "        10000:\"$10,000 - $20,000\",\n",
    "        90000:\"$90,000 - $100,000\",\n",
    "        30000:\"$30,000 - $40,000\",\n",
    "        20000:\"$20,000 - $30,000\",\n",
    "        70000:\"$70,000 - $80,000\",\n",
    "        80000:\"$80,000 - $90,000\",\n",
    "        50000:\"$50,000 - $60,000\",\n",
    "        60000:\"$60,000 - $70,000\",\n",
    "        140000:\"$140,000 - $150,000\",\n",
    "        130000:\"$130,000 - $140,000\",\n",
    "        100000:\"$100,000 - $110,000\",\n",
    "        110000:\"$110,000 - $120,000\",\n",
    "        160000:\"$160,000 - $170,000\",\n",
    "        180000:\"$180,000 - $190,000\",\n",
    "        120000:\"$120,000 - $130,000\",\n",
    "        150000:\"$150,000 - $160,000\",\n",
    "        190000:\"$190,000 - $200,000\",\n",
    "        170000:\"$170,000 - $180,000\"}\n",
    "\n",
    "# for less than $10,000 salary\n",
    "index = df_2019.ConvertedComp[(df_2019['ConvertedComp'] < 10000.0) & (df_2019['ConvertedComp'] != np.nan)].index\n",
    "df_2019.loc[index,'Salary_Range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    index = df_2019.ConvertedComp[(df_2019['ConvertedComp'] >= salary) & (df_2019['ConvertedComp'] < salary+step)].index\n",
    "    df_2019.loc[index,'Salary_Range']= dic[salary]\n",
    "    salary+=step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Man', nan, 'Woman',\n",
       "       'Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Man;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Man',\n",
       "       'Man;Non-binary, genderqueer, or gender non-conforming'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 'Man' with 'Male'\n",
    "df_2019.Gender.replace('Man', 'Male', inplace=True)\n",
    "\n",
    "# Replacing 'Woman' with 'Female'\n",
    "df_2019.Gender.replace('Woman', 'Female', inplace=True)\n",
    "\n",
    "# Replacing other fields with 'genderqueer'\n",
    "index = df_2019[~df_2019['Gender'].isin(['Male', 'Female', np.nan])].index\n",
    "df_2019.loc[index, 'Gender'] = 'genderqueer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"100 to 499 employees\",\"10,000 or more employees\",\n",
    "       \"10 to 19 employees\",\"20 to 99 employees\",\n",
    "       \"1,000 to 4,999 employees\",\"2-9 employees\",\n",
    "       \"500 to 999 employees\",\"5,000 to 9,999 employees\"]\n",
    "\n",
    "mod = [\"100-499\",\"10000+\",\"10-19\",\"20-99\",\"1000-4999\",\"<10\",\"500-999\",\"5000-9999\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2019.OrgSize.replace(col[i], mod[i], inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename and droping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Employment', 'Country', 'EdLevel', 'OrgSize', 'CareerSat', 'JobSat',\n",
       "       'ConvertedComp', 'Gender', 'UN_subregion', 'Continent',\n",
       "       'Formal_Education', 'Salary_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.rename(columns={'Employment':'Employment_Status',\n",
    "                       'OrgSize':'Company_Size', 'CareerSat':'Career_Satisfaction',\n",
    "                       'JobSat':'Job_Satisfaction'},\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.drop(columns=['ConvertedComp','EdLevel'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.to_csv(mod_df+\"2019.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected columns to read from 2020 dataset\n",
    "col_2020 = ['Age','CompTotal','ConvertedComp','Country','OrgSize',\n",
    "            'EdLevel','Employment','Gender',\n",
    "            'JobSat']\n",
    "\n",
    "df_2020 = pd.read_csv(survey+\"2020.csv.gz\", usecols=col_2020, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([          nan, 1.1600000e+05, 2.5000000e+04, ..., 1.2775000e+07,\n",
       "       2.7170564e+07, 4.3100000e+06])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.CompTotal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29705"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_2020['ConvertedComp'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country and contint\n",
    "There is one difference between the refrence list of countries and 2020 dataset **'Nomadic'** with 31 instance. We replace it with 'Other' to make it consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomadic \",\""
     ]
    }
   ],
   "source": [
    "# checking which countries have different name from this list and modify them for 2016 results. \n",
    "# It seems in 2015 similarity is ok\n",
    "unique_country =[]\n",
    "for x in df_2020.Country.unique():\n",
    "    unique_country.append(x)\n",
    "\n",
    "for x in unique_country:\n",
    "    if x not in uniques:\n",
    "        print(x,'\",\"',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#of differences between country continent refrence and 2020 dataset\n",
    "index = df_2020[df_2020.Country == 'Nomadic'].index\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020.loc[index, 'Country'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding subregion and continent columns\n",
    "subregion=[]\n",
    "continent=[] \n",
    "counter=0\n",
    "\n",
    "check_nan = df_2020['Country'].isnull()\n",
    "\n",
    "for i in range(df_2020.shape[0]):\n",
    "    x = df_2020.iloc[i]['Country']\n",
    "    if ~check_nan[i]:\n",
    "        subregion.append(df_country.loc[df_country['country']==x,'sub_region'].tolist()[0])\n",
    "        continent.append(df_country.loc[df_country['country']==x,'continent'].tolist()[0])\n",
    "            \n",
    "    else:\n",
    "        subregion.append(np.nan)\n",
    "        continent.append(np.nan)\n",
    "        counter+=1\n",
    "\n",
    "        \n",
    "# Adding two lists to dataframe if their length are equal to dataframe size\n",
    "if len(subregion)== df_2020.shape[0]:\n",
    "    df_2020['UN_subregion']=subregion\n",
    "else:\n",
    "    print('error: subregion size mismatch')\n",
    "\n",
    "        \n",
    "if len(subregion)== df_2020.shape[0]:\n",
    "        df_2020['Continent'] = continent\n",
    "else:\n",
    "        print('error: continent size mismatch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emplyment Status 'Employment' colum\n",
    "Checking the employment status values and make them consistent with other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Independent contractor, freelancer, or self-employed',\n",
       "       'Employed full-time', nan, 'Student',\n",
       "       'Not employed, but looking for work', 'Employed part-time',\n",
       "       'Retired', 'Not employed, and not looking for work'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020['Employment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Independent contractor, freelancer, or self-employed\",\n",
    "       \"Employed full-time\",\"Student\",\"Not employed, but looking for work\",\n",
    "       \"Employed part-time\",\"Retired\",\"Not employed, and not looking for work\"]\n",
    "\n",
    "mod = [\"Freelance / Contractor\",\"Employed full-time\",\n",
    "       \"Student\",\"Unemployed, looking for work\",\n",
    "       \"Employed part-time\",\"Retired\",\"Unemployed\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2020.Employment.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masterâs degree (M.A., M.S., M.Eng., MBA, etc.)',\n",
       "       'Bachelorâs degree (B.A., B.S., B.Eng., etc.)', nan,\n",
       "       'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
       "       'Professional degree (JD, MD, etc.)',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Associate degree (A.A., A.S., etc.)',\n",
       "       'Other doctoral degree (Ph.D., Ed.D., etc.)',\n",
       "       'Primary/elementary school',\n",
       "       'I never completed any formal education'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.EdLevel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "col =[\"Masterâs degree (M.A., M.S., M.Eng., MBA, etc.)\",\n",
    "      \"Bachelorâs degree (B.A., B.S., B.Eng., etc.)\",\n",
    "      \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\",\n",
    "      \"Professional degree (JD, MD, etc.)\",\n",
    "      \"Some college/university study without earning a degree\",\n",
    "      \"Associate degree (A.A., A.S., etc.)\",\n",
    "      \"Other doctoral degree (Ph.D., Ed.D., etc.)\",\n",
    "      \"Primary/elementary school\",\n",
    "      \"I never completed any formal education\"]\n",
    "\n",
    "mod = [\"Master's degree\",\"Bachelor's degree\",\"Secondary school\",\n",
    "       \"Professional degree\",\"Some college/university study without earning a bachelor's degree\",\n",
    "       \"Associate degree\",\"Doctoral degree\",\n",
    "       \"Primary/elementary school\",\"No formal education\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2020.EdLevel.replace(col[i], mod[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender\n",
    "In 2020 serveys answers for person gender are one of the following cases. For make it consistent we modify the column as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Man', nan, 'Woman',\n",
       "       'Man;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Man;Non-binary, genderqueer, or gender non-conforming',\n",
       "       'Woman;Man'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 'Man' with 'Male'\n",
    "df_2020.Gender.replace('Man', 'Male', inplace=True)\n",
    "\n",
    "# Replacing 'Woman' with 'Female'\n",
    "df_2020.Gender.replace('Woman', 'Female', inplace=True)\n",
    "\n",
    "# Replacing other fields with 'genderqueer'\n",
    "index = df_2020[~df_2020['Gender'].isin(['Male', 'Female', np.nan])].index\n",
    "df_2020.loc[index, 'Gender'] = 'genderqueer'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column\n",
    "df_2020['Salary_Range']=np.nan\n",
    "\n",
    "salary=10000\n",
    "step =10000\n",
    "up_bound=200000\n",
    "\n",
    "# using the following dictionary to replace values\n",
    "dic = {40000:\"$40,000 - $50,000\",\n",
    "        200000:\"More than $200,000\",\n",
    "        10000:\"$10,000 - $20,000\",\n",
    "        90000:\"$90,000 - $100,000\",\n",
    "        30000:\"$30,000 - $40,000\",\n",
    "        20000:\"$20,000 - $30,000\",\n",
    "        70000:\"$70,000 - $80,000\",\n",
    "        80000:\"$80,000 - $90,000\",\n",
    "        50000:\"$50,000 - $60,000\",\n",
    "        60000:\"$60,000 - $70,000\",\n",
    "        140000:\"$140,000 - $150,000\",\n",
    "        130000:\"$130,000 - $140,000\",\n",
    "        100000:\"$100,000 - $110,000\",\n",
    "        110000:\"$110,000 - $120,000\",\n",
    "        160000:\"$160,000 - $170,000\",\n",
    "        180000:\"$180,000 - $190,000\",\n",
    "        120000:\"$120,000 - $130,000\",\n",
    "        150000:\"$150,000 - $160,000\",\n",
    "        190000:\"$190,000 - $200,000\",\n",
    "        170000:\"$170,000 - $180,000\"}\n",
    "\n",
    "# for less than $10,000 salary\n",
    "index = df_2020.ConvertedComp[(df_2020['ConvertedComp'] < 10000.0) & (df_2020['ConvertedComp'] != np.nan)].index\n",
    "df_2019.loc[index,'Salary_Range']= 'Less than $10,000'\n",
    "\n",
    "# Between $10,000 to $190,000\n",
    "while salary <= up_bound:\n",
    "    index = df_2020.ConvertedComp[(df_2020['ConvertedComp'] >= salary) & (df_2020['ConvertedComp'] < salary+step)].index\n",
    "    df_2020.loc[index,'Salary_Range']= dic[salary]\n",
    "    salary+=step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'CompTotal', 'ConvertedComp', 'Country', 'EdLevel', 'Employment',\n",
       "       'Gender', 'JobSat', 'OrgSize', 'UN_subregion', 'Continent',\n",
       "       'Salary_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Range\n",
    "This datasets has ages in number. To be able to caterize them we create new columns as **'Age_Range'** and use df_2018 way to classify items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['25 - 34 years old', '35 - 44 years old', nan, '18 - 24 years old',\n",
       "       '45 - 54 years old', '55 - 64 years old', 'Under 18 years old',\n",
       "       '65 years or older'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.Age_Range.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty nan column added for category\n",
    "df_2020['Age_Range']=np.nan\n",
    "\n",
    "# Under 18 years old\n",
    "index = df_2020[(df_2020['Age'] < 18) & (df_2020['Age'] != np.nan)].index\n",
    "df_2020.loc[index, 'Age_Range'] = 'Under 18 years old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65 years or older \n",
    "index = df_2020[(df_2020['Age'] >= 65) & (df_2020['Age'] != np.nan)].index\n",
    "df_2020.loc[index, 'Age_Range'] = '65 years or older'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dic={(18,24):\"18 - 24 years old\",\n",
    "         (25,34):\"25 - 34 years old\",\n",
    "         (35,44):\"35 - 44 years old\",\n",
    "         (45,54):\"45 - 54 years old\",\n",
    "         (55,64):\"55 - 64 years old\",}\n",
    "\n",
    "for key in age_dic.keys():\n",
    "    low = key[0]\n",
    "    up =key[1]\n",
    "    index = df_2020[(df_2020['Age'] >= low) & (df_2020['Age'] <= up)].index\n",
    "    df_2020.loc[index, 'Age_Range'] = age_dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'CompTotal', 'ConvertedComp', 'Country', 'EdLevel', 'Employment',\n",
       "       'Gender', 'JobSat', 'OrgSize', 'UN_subregion', 'Continent',\n",
       "       'Salary_Range', 'Age_Range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2020.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"2 to 9 employees\",\"1,000 to 4,999 employees\",\n",
    "       \"20 to 99 employees\",\"10,000 or more employees\",\n",
    "       \"100 to 499 employees\",\"500 to 999 employees\",\n",
    "       \"10 to 19 employees\",\"5,000 to 9,999 employees\"]\n",
    "\n",
    "mod = [\"<10\",\"1000-4999\",\"20-99\",\"10000+\",\"100-499\",\"500-999\",\"10-19\",\"5000-9999\"]\n",
    "\n",
    "for i in range(len(col)):\n",
    "    df_2020.OrgSize.replace(col[i], mod[i], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming and dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming selected columns\n",
    "df_2020.rename(columns={'EdLevel':'Formal_Education',\n",
    "                       'Employment':'Employment_Status',\n",
    "                       'JobSat':'Job_Satisfaction',\n",
    "                       'OrgSize':'Company_Size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020.drop(columns=['Age', 'CompTotal', 'ConvertedComp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving 2020 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020.to_csv(mod_df+\"2020.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat all the dataframes\n",
    "To make it easier to compare the data at once, add column named year to each dataframe and then concatenate them in one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015['Year']=2015\n",
    "df_2016['Year']=2016\n",
    "df_2017['Year']=2017\n",
    "df_2018['Year']=2018\n",
    "df_2019['Year']=2019\n",
    "df_2020['Year']=2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_2015,df_2016, df_2017, df_2018, df_2019, df_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_2019.columns.sort)\n",
    "# print(df_2018.columns.sort)\n",
    "# print(df_2017.columns.sort)\n",
    "#print(df_2016.columns.sort)\n",
    "#print(df_2015.columns.sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving concatenated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(mod_df+\"all_years.csv.gz\", index=False, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '100-499', 'I am not part of a company', '10-19', '<10',\n",
       "       '20-99', '500-999', '1000-4999', '10000+', '5000-9999',\n",
       "       'I am not sure', 'I prefer not to answer', \"I don't know\", 'nan',\n",
       "       'Just me - I am a freelancer, sole proprietor, etc.'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.Company_Size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
